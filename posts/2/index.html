<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Deadlocks in the wild | dswij</title>
<meta name=keywords content><meta name=description content="Deadlock is a tale as old as concurrency, and I&rsquo;ve personally seen a fair share of it working with conventional, relational databases. But most recently, I stumbled upon a deadlock in h2
The issue With a really high max concurrent stream count with a huge payload in HTTP/2, combined with a high number of Futures in a single connection, hyper client quickly hung. The time it took to get stuck seems random at first, but after tweaking some settings here and there, I got it to hang after 5 request-response most of the time."><meta name=author content><link rel=canonical href=https://dswij.com/posts/2/><link crossorigin=anonymous href=/assets/css/stylesheet.min.60b8759a8e8db2cb14c1f11675c9e01ce5c8258ea99b8d7240073bf217345c7b.css integrity="sha256-YLh1mo6NsssUwfEWdcngHOXIJY6pm41yQAc78hc0XHs=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.js onload=hljs.initHighlightingOnLoad()></script><link rel=mask-icon href=https://dswij.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.123.8"></head><body id=top><script>document.body.classList.add("light")</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://dswij.com/ accesskey=h title="dswij (Alt + H)">dswij</a></div><ul id=menu><li><a href=https://dswij.com/ack/ title=Acknowledgement><span>Acknowledgement</span></a></li><li><a href=https://dswij.com/contact/ title="Contact me"><span>Contact me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Deadlocks in the wild</h1><div class=post-meta></div></header><div class=post-content><p>Deadlock is a tale as old as concurrency, and I&rsquo;ve personally seen a fair share of it working with conventional, relational databases. But most recently, I stumbled upon a deadlock in <a href=https://github.com/hyperium/h2><code>h2</code></a></p><h2 id=the-issue>The issue<a hidden class=anchor aria-hidden=true href=#the-issue>#</a></h2><p>With a really high max concurrent stream count with a huge payload in HTTP/2, combined with a high number of <code>Futures</code> in a single connection, <code>hyper</code> client quickly hung. The time it took to get stuck seems random at first, but after tweaking some settings here and there, I got it to hang after 5 request-response most of the time.</p><p>Number 5 seems weird. A coincidence, perhaps?</p><h2 id=debugging-it>Debugging it<a hidden class=anchor aria-hidden=true href=#debugging-it>#</a></h2><p>I decided to enable logging with <code>tracing_subscriber</code> and found out that it always hangs after it got into a certain state. More precisely, it happens when a stream tried to send a payload, but can&rsquo;t get enough connection capacity. HTTP/2 introduced a flow control strategy where it is basically a mechanism to handle connection and stream capacities on top of the TCP layer. This allows multiple streams in a single connection to stream data concurrenctly in any order.</p><p>With that in mind, let&rsquo;s look at the log. The funny thing is that it always hangs soon after this line: <code>stream capacity is 0</code>.</p><pre tabindex=0><code class=language-log data-lang=log>2023-11-18T16:49:56.726594Z TRACE Connection{peer=Client}:poll:pop_frame:popped{stream.id=StreamId(517) stream.state=State { inner: HalfClosedLocal(AwaitingHeaders) }}: h2::proto::streams::prioritize: stream capacity is 0
2023-11-18T16:49:56.726599Z TRACE Connection{peer=Client}:poll:FramedWrite::flush: h2::codec::framed_write: flushing buffer
2023-11-18T16:49:56.726603Z TRACE Connection{peer=Client}:poll: tokio::task::waker: op=&#34;waker.clone&#34; task.id=5
2023-11-18T16:49:56.726607Z TRACE Connection{peer=Client}:poll: tokio::task::waker: op=&#34;waker.drop&#34; task.id=5

# HANGS
</code></pre><p>Interesting. Let&rsquo;s dive into the code for a bit:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span>    <span style=color:#66d9ef>if</span> sz <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>&amp;&amp;</span> stream_capacity <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> {
</span></span><span style=display:flex><span>        tracing::trace!(<span style=color:#e6db74>&#34;stream capacity is 0&#34;</span>);
</span></span><span style=display:flex><span>        stream.pending_send.push_front(buffer, frame.into());
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>continue</span>;
</span></span><span style=display:flex><span>    }
</span></span></code></pre></div><p>It just run out of things that can be sent immediately because we don&rsquo;t have any capacity to send. Well, where did all the connection capacity go? Let&rsquo;s look at how we assign the pending capacity then:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span>    <span style=color:#75715e>// on receive WINDOW_UPDATE
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span> stream.send_flow.available() <span style=color:#f92672>&lt;</span> stream.requested_send_capacity <span style=color:#66d9ef>as</span> <span style=color:#66d9ef>usize</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>&amp;&amp;</span> stream.send_flow.has_unavailable()
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// The stream requires additional capacity and the stream&#39;s
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// window has available capacity, but the connection window
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// does not.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>//
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// In this case, the stream needs to be queued up for when the
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// connection has more capacity.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        self.pending_capacity.push(stream);
</span></span><span style=display:flex><span>    }
</span></span></code></pre></div><p>prying on <code>pending_capacity</code>, there&rsquo;s not only <code>max_concurrent_stream</code> amount of stream there. All the <code>Futures</code> are in pending_capacity. Aha! Now the deadlock sensor is tingling all over the place.</p><p>Ok, that&rsquo;s cool. But I hadn&rsquo;t really figure out why it got stuck after 5 request or why it got stuck at all! Yes, the capacity is poorly placed to non-sending streams, but that&rsquo;s all we have right now.</p><p>Upon further inspection, there are a couple of things that stood out:</p><ol><li>the server sent back WINDOW_UPDATE frames in small increments.</li><li>the payload max size is <code>5 * the max body buffer size</code>.</li><li>streams are put back to <code>pending_capacity</code> in a LIFO-manner.</li></ol><p>That&rsquo;s the problem. The inert Futures waiting in <code>pending_capacity</code> is just hogging all the connection capacity. We&rsquo;re left without any capacity for sending messages in send-ready streams.</p><h2 id=the-fix>The fix<a hidden class=anchor aria-hidden=true href=#the-fix>#</a></h2><p>A really easy fix is to probably to put those ready to send in front of the queue. And it works perfectly fine.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span>    <span style=color:#75715e>// if the stream needs capacity we add:
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span> stream.is_send_ready() {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Prioritize assigning capacity to a send-ready stream
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        self.pending_capacity.push_front(stream);
</span></span><span style=display:flex><span>    } <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>        self.pending_capacity.push(stream);
</span></span><span style=display:flex><span>    }
</span></span></code></pre></div><p>But this runs into a problem when all the send-ready streams sent some of their payload, while we receive a WINDOW_UPDATE frames. Those streams are not in <code>pending_capacity</code> when this happens and some of the connection capacity will go to those inert streams. This won&rsquo;t get to a deadlock, but the connection capacity will be distributed poorly.</p><p>Let&rsquo;s fix that again:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span>    <span style=color:#75715e>// on receiving WINDOW_UPDATE
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>!</span>stream.is_pending_open {
</span></span><span style=display:flex><span>        self.try_assign_capacity(stream);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// somewhere in the code when we can open another stream
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span> <span style=color:#66d9ef>let</span> Some(<span style=color:#66d9ef>mut</span> stream) <span style=color:#f92672>=</span> self.pop_pending_open(store, counts) {
</span></span><span style=display:flex><span>        self.pending_send.push_front(<span style=color:#f92672>&amp;</span><span style=color:#66d9ef>mut</span> stream);
</span></span><span style=display:flex><span>        self.try_assign_capacity(<span style=color:#f92672>&amp;</span><span style=color:#66d9ef>mut</span> stream);
</span></span><span style=display:flex><span>    }
</span></span></code></pre></div><p>Done! that&rsquo;s neat.</p><h2 id=what-now>What now?<a hidden class=anchor aria-hidden=true href=#what-now>#</a></h2><p>Well, the flow control in HTTP/2 turns out to be challenging. Since <code>h2</code>&rsquo;s implementation is eager on assigning capacity, combining it with another <code>Semaphore</code> leads to another <a href=https://github.com/hyperium/hyper/issues/3559>deadlock</a>!</p><p>But that&rsquo;s for another post.</p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://dswij.com/>dswij</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</button>
</a><script>let menu=document.getElementById("menu");menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script type=module src=https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js></script><script nomodule src=https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js></script></body></html>